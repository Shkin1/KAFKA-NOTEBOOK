线上环境要考虑各种因素

磁盘
网络
操作系统
...... 等等因素考虑




OS方面  :  linux 更胜一筹
I/O 模型的使用
数据网络传输效率
社区支持度

I/O 模型与 Kafka 的关系又是什么呢？实际上 Kafka 客户端底层使用了 Java的 selector，selector 在 Linux 上的实现机制是 epoll，
而在 Windows 平台上的实现机制是 select。因此在这一点上将 Kafka 部署在 Linux 上是有优势的，因为能够获得更高效的I/O 性能


磁盘方面 :  
Kafka 大量使用磁盘不假，可它使用的方式多是顺序读写操作，一定程度上规避了机械磁盘
最大的劣势，即随机读写操作慢。从这一点上来说，使用 SSD 似乎并没有太大的性能优
势，毕竟从性价比上来说，机械磁盘物美价廉，而它因易损坏而造成的可靠性差等缺陷，又
由 Kafka 在软件层面提供机制来保证，故使用普通机械磁盘是很划算的。



磁盘容量:

1. kafka集群到底需要多大的存储空间呢? 每天100G数据量如何进行规划?

我举一个简单的例子来说明该如何思考这个问题。假设你所在公司有个业务每天需要向
Kafka 集群发送 1 亿条消息，每条消息保存两份以防止数据丢失，另外消息默认保存两周
时间。现在假设消息的平均大小是 1KB，那么你能说出你的 Kafka 集群需要为这个业务预
留多少磁盘空间吗？


我们来计算一下：每天 1 亿条 1KB 大小的消息，保存两份且留存两周的时间，那么总的空
间大小就等于 1 亿 * 1KB * 2 / 1000 / 1000 = 200GB。一般情况下 Kafka 集群除了消息
数据还有其他类型的数据，比如索引数据等，故我们再为这些数据预留出 10% 的磁盘空
间，因此总的存储容量就是 220GB。既然要保存两周，那么整体容量即为 220GB * 14，
大约 3TB 左右。Kafka 支持数据的压缩，假设压缩比是 0.75，那么最后你需要规划的存储
空间就是 0.75 * 3 = 2.25TB。



带宽规划 (计算规划得出 100GB/1小时的场景,只需要3台, 1TB 需要30台):
对于 Kafka 这种通过网络大量进行数据传输的框架而言，带宽特别容易成为瓶颈。事实
上，在我接触的真实案例当中，带宽资源不足导致 Kafka 出现性能问题的比例至少占 60%
以上。如果你的环境中还涉及跨机房传输，那么情况可能就更糟了。

带宽一般主要为: 1Gbps 千兆网络   /     10Gbps万兆网络
 

      如果你不是超级土豪的话，我会认为你和我平时使用的都是普通的以太网络，带宽也主要有
两种：1Gbps 的千兆网络和 10Gbps 的万兆网络，特别是千兆网络应该是一般公司网络的
标准配置了。下面我就以千兆网络举一个实际的例子，来说明一下如何进行带宽资源的规划。

      与其说是带宽资源的规划，其实真正要规划的是所需的 Kafka 服务器的数量。假设你公司
的机房环境是千兆网络，即 1Gbps，现在你有个业务，其业务目标或 SLA 是在 1 小时内处
理 1TB 的业务数据。那么问题来了，你到底需要多少台 Kafka 服务器来完成这个业务呢？


一台传输的能力 ===> 1Gbps * 70%(阈值) = 700Mb  * 1/3(实际利用) = 244Mbps (其实也就大概只剩二三十兆MB/s了)

那么1小时内处理1TB数据所需要的机器数量? 

1TB => 1000*1000*8 / 3600s =  每秒需要处理 2336Mb 的数据

2336 / 244 = 10台 * 3(备份) = 30台


100GB = 100 * 1000 * 8 / 3600s = 222 Mb
222 / 244  = 1台 * 3(备份) = 3台





